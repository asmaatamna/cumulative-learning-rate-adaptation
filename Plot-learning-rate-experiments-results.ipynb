{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "%matplotlib qt"
   ],
   "id": "fa66c3b5861ac4f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def summarize_metric_sweep_lr(base_dir, algorithms, datasets, lr_values, metric=\"test_accuracy\"):\n",
    "    \"\"\"\n",
    "    Computes mean and std of a specified metric (e.g., test_accuracy or test_loss) over seeds,\n",
    "    for each learning rate in `lr_values`. Displays results by algorithm (rows) and dataset (columns),\n",
    "    grouped by learning rate with the LR value shown only once per block.\n",
    "\n",
    "    Returns:\n",
    "        summary_stats: dict[lr][algorithm][dataset] = (mean, std)\n",
    "    \"\"\"\n",
    "\n",
    "    # folder_pattern = re.compile(r\"(\\d{4}-\\d{2}-\\d{2})_(\\d{2}-\\d{2})_(\\d+)_([\\d]+)\")\n",
    "    folder_pattern = re.compile(r\"(\\d+)_([\\d]+)_EpochSeed\")\n",
    "\n",
    "    # Store results: {lr -> algorithm -> dataset -> values}\n",
    "    summary_stats = defaultdict(lambda: defaultdict(dict))\n",
    "    all_rows = []\n",
    "\n",
    "    for lr_value in lr_values:\n",
    "        results = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "        for entry in os.listdir(base_dir):\n",
    "            if not folder_pattern.match(entry):\n",
    "                continue\n",
    "            run_dir = os.path.join(base_dir, entry)\n",
    "\n",
    "            for dataset in datasets:\n",
    "                dataset_path = os.path.join(run_dir, dataset)\n",
    "                lr_folder = os.path.join(dataset_path, f\"lr{lr_value}\")\n",
    "                if not os.path.isdir(lr_folder):\n",
    "                    continue\n",
    "\n",
    "                for algorithm in algorithms:\n",
    "                    result_file = os.path.join(lr_folder, f\"{algorithm}.pkl\")\n",
    "                    if os.path.isfile(result_file):\n",
    "                        with open(result_file, 'rb') as f:\n",
    "                            data = pickle.load(f)\n",
    "                            val = data.get(metric)\n",
    "                            if val is not None:\n",
    "                                results[algorithm][dataset].append(val)\n",
    "\n",
    "        # Compute mean/std for this learning rate\n",
    "        for algorithm in algorithms:\n",
    "            row = [lr_value if algorithm == algorithms[0] else \"\", algorithm]\n",
    "            for dataset in datasets:\n",
    "                vals = results[algorithm][dataset]\n",
    "                if vals:\n",
    "                    mean_val = np.mean(vals)\n",
    "                    std_val = np.std(vals)\n",
    "                    summary_stats[lr_value][algorithm][dataset] = (mean_val, std_val)\n",
    "                    row.append(f\"{mean_val:.4f} Â± {std_val:.4f}\")\n",
    "                else:\n",
    "                    summary_stats[lr_value][algorithm][dataset] = None\n",
    "                    row.append(\"-\")\n",
    "            all_rows.append(row)\n",
    "\n",
    "    # Build headers\n",
    "    headers = [\"LR\", \"Algorithm\"] + datasets\n",
    "    table_str = tabulate(all_rows, headers=headers, tablefmt=\"fancy_grid\")\n",
    "    print(table_str)\n",
    "    return summary_stats"
   ],
   "id": "f379bde004db3a6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_algorithm_colors(algorithms):\n",
    "    \"\"\"\n",
    "    Returns a dictionary mapping each algorithm to a distinct color from the 'tab10' colormap.\n",
    "    \"\"\"\n",
    "\n",
    "    # num_colors = len(algorithms)\n",
    "    # colormap = plt.get_cmap('tab10', num_colors)\n",
    "    # color_map = {algorithm: colormap(i) for i, algorithm in enumerate(algorithms)}\n",
    "    color_map = {\n",
    "        \"SGD\": \"blue\",\n",
    "        \"SGD_CLARA\": \"dodgerblue\",\n",
    "        \"SGD_CLARA_us\": \"cyan\",\n",
    "\n",
    "        \"Adam\": \"red\",\n",
    "        \"Adam_CLARA\": \"coral\",  # \"deeppink\",\n",
    "        \"Adam_CLARA_us\": \"magenta\",\n",
    "\n",
    "        \"D-Adaptation\": \"green\"\n",
    "    }\n",
    "    return color_map"
   ],
   "id": "c4829c660974e782",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_algorithm_performance(summary_stats, algorithms, datasets, lr_values, metric_name=\"Test Accuracy\"):\n",
    "    \"\"\"\n",
    "    Plot bar charts with error bars showing mean and std for each algorithm at different learning rates,\n",
    "    one plot per dataset, with improved spacing, consistent y-axis, a horizontal line for best performance,\n",
    "    and transparency on non-best bars. Each algorithm is assigned a consistent color.\n",
    "    \"\"\"\n",
    "\n",
    "    num_lrs = len(lr_values)\n",
    "    num_algos = len(algorithms)\n",
    "    bar_width = 0.15\n",
    "    group_spacing = 0.4  # space between groups\n",
    "    total_group_width = num_algos * bar_width + group_spacing\n",
    "    x = np.arange(num_lrs) * total_group_width\n",
    "\n",
    "    color_map = get_algorithm_colors(algorithms)\n",
    "\n",
    "    for dataset in datasets:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        all_means = []  # store all means to compute the best one\n",
    "\n",
    "        # First, gather all means to find the best one\n",
    "        for algorithm in algorithms:\n",
    "            for lr in lr_values:\n",
    "                stats = summary_stats.get(lr, {}).get(algorithm, {}).get(dataset)\n",
    "                if stats is not None:\n",
    "                    mean, _ = stats\n",
    "                    all_means.append((mean, algorithm, lr))\n",
    "\n",
    "        if not all_means:\n",
    "            continue  # skip empty plots\n",
    "\n",
    "        # Find the best performing (mean) algorithm-lr pair\n",
    "        best_mean, best_algo, best_lr = max(all_means, key=lambda x: x[0])\n",
    "\n",
    "        for i, algorithm in enumerate(algorithms):\n",
    "            means = []\n",
    "            stds = []\n",
    "            alphas = []\n",
    "\n",
    "            for lr in lr_values:\n",
    "                stats = summary_stats.get(lr, {}).get(algorithm, {}).get(dataset)\n",
    "                if stats is not None:\n",
    "                    mean, std = stats\n",
    "                else:\n",
    "                    mean, std = 0, 0\n",
    "                means.append(mean)\n",
    "                stds.append(std)\n",
    "\n",
    "                # Make best bar opaque, others semi-transparent\n",
    "                if algorithm == best_algo and lr == best_lr:\n",
    "                    alphas.append(1.0)\n",
    "                else:\n",
    "                    alphas.append(0.5)\n",
    "\n",
    "            x_pos = x + i * bar_width\n",
    "            bars = plt.bar(x_pos, means, width=bar_width, label=algorithm, yerr=stds,\n",
    "                           capsize=5, color=color_map[algorithm])\n",
    "\n",
    "            # Adjust alpha bar by bar\n",
    "            for bar, a in zip(bars, alphas):\n",
    "                bar.set_alpha(a)\n",
    "\n",
    "        # Add horizontal line at best performance\n",
    "        plt.axhline(y=best_mean, color='gray', linestyle='--', linewidth=1)\n",
    "        plt.text(x[0] - bar_width * 3.9, best_mean, f\"{best_mean:.2f}\", va='center', ha='right', color='gray')\n",
    "\n",
    "        # Plot styling\n",
    "        plt.xticks(x + (num_algos / 2 - 0.5) * bar_width, lr_values)\n",
    "        plt.xlabel(\"Learning Rate\")\n",
    "        plt.ylabel(metric_name)\n",
    "        plt.title(f\"{metric_name} on {dataset}\")\n",
    "        plt.ylim(0, 100)\n",
    "        plt.legend()\n",
    "        plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ],
   "id": "5de6ddbc031580e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "summary = summarize_metric_sweep_lr(\n",
    "    base_dir=\"Experiments/selected_results/\",\n",
    "    algorithms=[\"SGD\", \"SGD_CLARA\", \"SGD_CLARA_us\", \"Adam\", \"Adam_CLARA\", \"Adam_CLARA_us\", \"D-Adaptation\"],\n",
    "    datasets=[\"breast_cancer\", \"iris\", \"wine\", \"digits\", \"mnist\", \"fmnist\", \"cifar10\", \"cifar100\"],\n",
    "    lr_values=[\"1e-06\", \"1e-05\", \"1e-04\", \"1e-03\", \"1e-02\", \"1e-01\", \"1.00\"],  # must match folder name exactly\n",
    "    metric=\"test_accuracy\"  # test_accuracy or test_loss\n",
    ")"
   ],
   "id": "3e8d45ebebaddf99",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plot_algorithm_performance(\n",
    "    summary_stats=summary,  # from earlier function\n",
    "    algorithms=[\"SGD\", \"SGD_CLARA\", \"SGD_CLARA_us\", \"Adam\", \"Adam_CLARA\", \"Adam_CLARA_us\", \"D-Adaptation\"],\n",
    "    datasets=[\"breast_cancer\", \"iris\", \"wine\", \"digits\", \"mnist\", \"fmnist\", \"cifar10\", \"cifar100\"],\n",
    "    lr_values=[\"1e-06\", \"1e-05\", \"1e-04\", \"1e-03\", \"1e-02\", \"1e-01\", \"1.00\"],\n",
    "    metric_name=\"Test Accuracy\"\n",
    ")"
   ],
   "id": "4998973b9c860ddb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_algorithm_performance_lines(summary_stats, algorithms, datasets, lr_values, metric_name=\"Test Accuracy\", save_fig=False):\n",
    "    \"\"\"\n",
    "    Plot line charts (instead of bar plots) with error bars for each algorithm at different learning rates,\n",
    "    one plot per dataset. Each algorithm is represented by a different color and marker.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_markers():\n",
    "        return ['o', 's', '^', 'D', 'v', 'P', '>', 'X', 'h', '+']\n",
    "\n",
    "    color_map = get_algorithm_colors(algorithms)\n",
    "    marker_list = get_markers()\n",
    "\n",
    "    for dataset in datasets:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        # Keeping track of the best test performance across algorithms and learning rate values\n",
    "        global_best = {\"val\": -np.inf, \"lr\": None, \"algo\": None}\n",
    "\n",
    "        for i, algorithm in enumerate(algorithms):\n",
    "            means = []\n",
    "            stds = []\n",
    "\n",
    "            for lr in lr_values:\n",
    "                val = summary_stats.get(lr, {}).get(algorithm, {}).get(dataset)\n",
    "                if val:\n",
    "                    mean, std = val\n",
    "                else:\n",
    "                    mean, std = np.nan, np.nan\n",
    "                means.append(mean)\n",
    "                stds.append(std)\n",
    "\n",
    "            # Convert learning rates to float for plotting\n",
    "            lr_floats = [float(lr) for lr in lr_values]\n",
    "            plt.errorbar(\n",
    "                lr_floats,\n",
    "                means,\n",
    "                yerr=stds,\n",
    "                label=algorithm,\n",
    "                marker=marker_list[i % len(marker_list)],\n",
    "                markersize=8,\n",
    "                color=color_map[algorithm],\n",
    "                capsize=4,\n",
    "                linestyle='-'\n",
    "            )\n",
    "\n",
    "            # Track global best point\n",
    "            max_val = np.nanmax(means)\n",
    "            if max_val > global_best[\"val\"]:\n",
    "                best_idx = np.nanargmax(means)\n",
    "                global_best = {\n",
    "                    \"val\": max_val,\n",
    "                    \"lr\": float(lr_values[best_idx]),\n",
    "                    \"algo\": algorithm\n",
    "                }\n",
    "\n",
    "        # Highlight best overall performance\n",
    "        plt.plot(\n",
    "            global_best[\"lr\"], global_best[\"val\"],\n",
    "            marker='*', color='black', markersize=15,\n",
    "            label=\"Best overall\", zorder=5\n",
    "        )\n",
    "        plt.text(\n",
    "            global_best[\"lr\"], global_best[\"val\"] + 1.5,\n",
    "            f\"{global_best['val']:.2f}\",\n",
    "            ha='center', va='bottom',\n",
    "            fontsize=9, color='black', fontweight='bold'\n",
    "        )\n",
    "\n",
    "        plt.xscale(\"log\")\n",
    "        plt.xlabel(\"Initial Learning Rate\")\n",
    "        plt.ylabel(metric_name)\n",
    "        # plt.title(f\"{metric_name} on {dataset}\")\n",
    "        plt.title(f\"{dataset}\")\n",
    "        plt.ylim(0, 100)\n",
    "        plt.grid(True, which='both', linestyle='--', alpha=0.7)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save as PDF in a subdirectory\n",
    "        if save_fig:\n",
    "            save_dir = \"plots\"\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "            filename = f\"{dataset}_{metric_name.replace(' ', '_')}.pdf\"\n",
    "            filepath = os.path.join(save_dir, filename)\n",
    "            plt.savefig(filepath, format='pdf', bbox_inches='tight')\n",
    "\n",
    "        plt.show()"
   ],
   "id": "97d19721bc900bca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plot_algorithm_performance_lines(\n",
    "    summary_stats=summary,\n",
    "    algorithms=[\"SGD\", \"SGD_CLARA\", \"SGD_CLARA_us\", \"Adam\", \"Adam_CLARA\", \"Adam_CLARA_us\", \"D-Adaptation\"],\n",
    "    # algorithms=[\"SGD_CLARA\", \"SGD_CLARA_us\", \"Adam_CLARA\", \"Adam_CLARA_us\"],\n",
    "    datasets=[\"breast_cancer\", \"iris\", \"wine\", \"digits\", \"mnist\", \"fmnist\", \"cifar10\", \"cifar100\"],\n",
    "    lr_values=[\"1e-06\", \"1e-05\", \"1e-04\", \"1e-03\", \"1e-02\", \"1e-01\", \"1.00\"],\n",
    "    metric_name=\"Test Accuracy\",\n",
    "    save_fig=False\n",
    ")"
   ],
   "id": "64974bd63f808ee4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_avg_performance_vs_damping(base_dir, algorithm, datasets, lr_values, metric=\"test_accuracy\"):\n",
    "    \"\"\"\n",
    "    For a given algorithm, plot average test performance across all datasets (with std deviation as error bars)\n",
    "    as a function of damping value. Each line corresponds to a different learning rate.\n",
    "    \"\"\"\n",
    "    # Pattern: date_time_epoch_seed_damping\n",
    "    # folder_pattern = re.compile(r\"(\\d{4}-\\d{2}-\\d{2})_(\\d{2}-\\d{2})_(\\d+)_([\\d]+)_([0-9eE\\.-]+)\")\n",
    "    folder_pattern = re.compile(r\"(\\d+)_([\\d]+)_([0-9eE\\.-]+)_EpochSeedDamping\")\n",
    "\n",
    "    # results[damping][lr] = list of metric values (avg over datasets and seeds)\n",
    "    results = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "    for entry in os.listdir(base_dir):\n",
    "        match = folder_pattern.match(entry)\n",
    "        if not match:\n",
    "            continue\n",
    "        _, _, damping = match.groups()\n",
    "        damping = float(damping)\n",
    "        run_dir = os.path.join(base_dir, entry)\n",
    "\n",
    "        for dataset in datasets:\n",
    "            dataset_path = os.path.join(run_dir, dataset)\n",
    "            if not os.path.isdir(dataset_path):\n",
    "                continue\n",
    "\n",
    "            for lr in lr_values:\n",
    "                lr_path = os.path.join(dataset_path, f\"lr{lr}\")\n",
    "                result_file = os.path.join(lr_path, f\"{algorithm}.pkl\")\n",
    "                if os.path.isfile(result_file):\n",
    "                    with open(result_file, \"rb\") as f:\n",
    "                        data = pickle.load(f)\n",
    "                        value = data.get(metric)\n",
    "                        if value is not None:\n",
    "                            results[damping][lr].append(value)\n",
    "\n",
    "    # Sort damping values\n",
    "    damping_values = sorted(results.keys())\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    for lr in lr_values:\n",
    "        means = []\n",
    "        stds = []\n",
    "        for damping in damping_values:\n",
    "            vals = results[damping].get(lr, [])\n",
    "            if vals:\n",
    "                means.append(np.mean(vals))\n",
    "                stds.append(np.std(vals))\n",
    "            else:\n",
    "                means.append(np.nan)\n",
    "                stds.append(np.nan)\n",
    "\n",
    "        plt.errorbar(damping_values, means, yerr=stds, marker='o', label=f\"lr={lr}\", capsize=4)\n",
    "\n",
    "    plt.xscale(\"log\")\n",
    "    plt.xlabel(\"Damping\")\n",
    "    plt.ylabel(metric.replace(\"_\", \" \").capitalize())\n",
    "    plt.title(f\"Performance over all datasets for {algorithm}\")\n",
    "    plt.ylim(0, 100)\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save plot\n",
    "    save_dir = \"plots_vs_damping\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    filename = f\"{algorithm}_{metric}.pdf\"\n",
    "    filepath = os.path.join(save_dir, filename)\n",
    "    plt.savefig(filepath, format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()"
   ],
   "id": "f1bb79b685ff29ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plot_avg_performance_vs_damping(\n",
    "    base_dir=\"Experiments/selected_results/damping_experiments/\",\n",
    "    algorithm=\"SGD_CLARA_us\",\n",
    "    datasets=[\"breast_cancer\", \"iris\", \"wine\", \"digits\", \"mnist\", \"fmnist\", \"cifar10\", \"cifar100\"],\n",
    "    lr_values=[\"1e-06\", \"1e-05\", \"1e-04\", \"1e-03\", \"1e-02\", \"1e-01\", \"1.00\"],\n",
    "    metric=\"test_accuracy\"\n",
    ")"
   ],
   "id": "c378859e6cf97783",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_performance_vs_damping_per_dataset(base_dir, algorithm, datasets, lr_values, metric=\"test_accuracy\"):\n",
    "    \"\"\"\n",
    "    For a given algorithm, plot test performance as a function of damping (with error bars) for each dataset\n",
    "    and each learning rate. Also plots best damping as a function of learning rate.\n",
    "    \"\"\"\n",
    "    folder_pattern = re.compile(r\"(\\d+)_([\\d]+)_([0-9eE\\.-]+)_EpochSeedDamping\")\n",
    "\n",
    "    for dataset in datasets:\n",
    "        results = defaultdict(lambda: defaultdict(list))  # results[damping][lr] = list of metric values\n",
    "\n",
    "        for entry in os.listdir(base_dir):\n",
    "            match = folder_pattern.match(entry)\n",
    "            if not match:\n",
    "                continue\n",
    "            _, _, damping = match.groups()\n",
    "            damping = float(damping)\n",
    "            run_dir = os.path.join(base_dir, entry)\n",
    "\n",
    "            dataset_path = os.path.join(run_dir, dataset)\n",
    "            if not os.path.isdir(dataset_path):\n",
    "                continue\n",
    "\n",
    "            for lr in lr_values:\n",
    "                lr_path = os.path.join(dataset_path, f\"lr{lr}\")\n",
    "                result_file = os.path.join(lr_path, f\"{algorithm}.pkl\")\n",
    "                if os.path.isfile(result_file):\n",
    "                    with open(result_file, \"rb\") as f:\n",
    "                        data = pickle.load(f)\n",
    "                        value = data.get(metric)\n",
    "                        if value is not None:\n",
    "                            results[damping][lr].append(value)\n",
    "\n",
    "        damping_values = sorted(results.keys())\n",
    "        best_dampings = []\n",
    "\n",
    "        # Plot: performance vs. damping (1 plot per dataset)\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        for lr in lr_values:\n",
    "            means, stds = [], []\n",
    "            for damping in damping_values:\n",
    "                vals = results[damping].get(lr, [])\n",
    "                if vals:\n",
    "                    means.append(np.mean(vals))\n",
    "                    stds.append(np.std(vals))\n",
    "                else:\n",
    "                    means.append(np.nan)\n",
    "                    stds.append(np.nan)\n",
    "\n",
    "            # Get best damping for this lr\n",
    "            valid = [(d, m) for d, m in zip(damping_values, means) if not np.isnan(m)]\n",
    "            if valid:\n",
    "                best_damping, best_value = max(valid, key=lambda x: x[1])\n",
    "                best_dampings.append((float(lr), best_damping))\n",
    "\n",
    "                # Copy best model to target folder\n",
    "                for s in range(5):\n",
    "                    source_path = f\"Experiments/selected_results/damping_experiments/100_{s}_{best_damping:.0e}_EpochSeedDamping/{dataset}/lr{lr}/{algorithm}.pkl\"\n",
    "                    dest_path = f\"Experiments/selected_results/100_{s}_EpochSeed/{dataset}/lr{lr}/\"\n",
    "                    os.makedirs(dest_path, exist_ok=True)\n",
    "                    if os.path.exists(source_path):\n",
    "                        shutil.copy(source_path, dest_path)\n",
    "\n",
    "            plt.errorbar(\n",
    "                damping_values, means, yerr=stds,\n",
    "                marker='o', label=f\"lr={lr}\", capsize=5\n",
    "            )\n",
    "\n",
    "        plt.xscale(\"log\")\n",
    "        plt.xlabel(\"Damping\")\n",
    "        plt.ylabel(metric.replace(\"_\", \" \").title())\n",
    "        plt.title(f\"{algorithm} on {dataset}\")\n",
    "        plt.legend()\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.ylim(0, 100)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save performance vs damping plot\n",
    "        save_dir = \"plots_vs_damping\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        filename = f\"{dataset}_{algorithm}_{metric}.pdf\"\n",
    "        filepath = os.path.join(save_dir, filename)\n",
    "        plt.savefig(filepath, format=\"pdf\", bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "        # Plot: best damping vs. learning rate\n",
    "        if best_dampings:\n",
    "            lr_floats, best_damp_vals = zip(*sorted(best_dampings))\n",
    "\n",
    "            plt.figure(figsize=(7, 5))\n",
    "            plt.plot(lr_floats, best_damp_vals, marker='o', linestyle='-')\n",
    "            plt.xscale(\"log\")\n",
    "            plt.yscale(\"log\")\n",
    "            plt.yscale(\"log\")\n",
    "            plt.ylim(1e-5, 1e-1)\n",
    "            plt.xlabel(\"Initial Learning Rate\")\n",
    "            plt.ylabel(\"Best Damping\")\n",
    "            plt.title(f\"Best Damping vs Learning Rate\\n{algorithm} on {dataset}\")\n",
    "            plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "            plt.tight_layout()\n",
    "\n",
    "            # Save best damping vs learning rate plot\n",
    "            best_plot_dir = \"plots_best_damping\"\n",
    "            os.makedirs(best_plot_dir, exist_ok=True)\n",
    "            best_filename = f\"{dataset}_{algorithm}_{metric}_best_damping_vs_lr.pdf\"\n",
    "            best_filepath = os.path.join(best_plot_dir, best_filename)\n",
    "            plt.savefig(best_filepath, format=\"pdf\", bbox_inches=\"tight\")\n",
    "            plt.close()"
   ],
   "id": "25f57edd9b1e6954",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plot_performance_vs_damping_per_dataset(\n",
    "    base_dir=\"Experiments/selected_results/damping_experiments/\",\n",
    "    algorithm=\"SGD_CLARA_us\",\n",
    "    datasets=[\"breast_cancer\", \"iris\", \"wine\", \"digits\", \"mnist\", \"fmnist\", \"cifar10\", \"cifar100\"],\n",
    "    lr_values=[\"1e-06\", \"1e-05\", \"1e-04\", \"1e-03\", \"1e-02\", \"1e-01\", \"1.00\"],\n",
    "    metric=\"test_accuracy\"\n",
    ")"
   ],
   "id": "1da857c8550930e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_avg_lr_and_accuracy_schedules(base_dir_template, seeds, dataset, algorithms):\n",
    "    \"\"\"\n",
    "    For each algorithm, plot average learning rate and training accuracy schedules across seeds,\n",
    "    grouped by initial learning rate. Plots appear in two stacked subplots with a shared legend.\n",
    "    \"\"\"\n",
    "    for algorithm in algorithms:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5), sharey=False)\n",
    "\n",
    "        example_dir = base_dir_template.format(seeds[0])\n",
    "        dataset_path = os.path.join(example_dir, dataset)\n",
    "        lr_folders = [f for f in os.listdir(dataset_path) if f.startswith(\"lr\")]\n",
    "\n",
    "        lr_entries = []\n",
    "        for folder in lr_folders:\n",
    "            try:\n",
    "                lr_str = folder[2:]\n",
    "                lr_float = float(lr_str)\n",
    "                lr_entries.append((lr_str, lr_float))\n",
    "            except ValueError:\n",
    "                continue\n",
    "        lr_entries.sort(key=lambda x: x[1])\n",
    "\n",
    "        for lr_str, _ in lr_entries:\n",
    "            lr_histories = []\n",
    "            acc_histories = []\n",
    "\n",
    "            for seed in seeds:\n",
    "                base_dir = base_dir_template.format(seed)\n",
    "                pkl_path = os.path.join(base_dir, dataset, f\"lr{lr_str}\", f\"{algorithm}.pkl\")\n",
    "                if os.path.isfile(pkl_path):\n",
    "                    with open(pkl_path, \"rb\") as f:\n",
    "                        data = pickle.load(f)\n",
    "                        lr_history = data.get(\"lr_history\")\n",
    "\n",
    "                        # contains_nan = np.isnan(lr_history).any()\n",
    "                        # if contains_nan:\n",
    "                        #     print(lr_history)\n",
    "\n",
    "                        acc_history = data.get(\"train_accuracies\")\n",
    "                        if lr_history is not None and acc_history is not None:\n",
    "                            lr_histories.append(lr_history)\n",
    "                            acc_histories.append(acc_history)\n",
    "\n",
    "            if not lr_histories:\n",
    "                continue\n",
    "\n",
    "            # Compute mean and std\n",
    "            lr_array = np.array(lr_histories)\n",
    "            acc_array = np.array(acc_histories)\n",
    "            mean_lr = np.mean(lr_array, axis=0)\n",
    "            std_lr = np.std(lr_array, axis=0)\n",
    "            mean_acc = np.mean(acc_array, axis=0)\n",
    "            std_acc = np.std(acc_array, axis=0)\n",
    "            steps = np.arange(len(mean_lr))\n",
    "\n",
    "            label = f\"lr={lr_str}\"\n",
    "            ax2.plot(steps, mean_lr, label=label)\n",
    "            ax2.fill_between(steps, mean_lr - std_lr, mean_lr + std_lr, alpha=0.2)\n",
    "\n",
    "            ax1.plot(steps, mean_acc, label=label)\n",
    "            ax1.fill_between(steps, mean_acc - std_acc, mean_acc + std_acc, alpha=0.2)\n",
    "\n",
    "        plt.suptitle(f\"{algorithm} on {dataset}\")\n",
    "\n",
    "        # Format bottom plot (learning rate)\n",
    "        ax2.set_xlabel(\"Epoch\")\n",
    "        ax2.set_yscale(\"log\")\n",
    "        ax2.set_ylabel(\"Learning Rate\")\n",
    "        ax2.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "        # Format top plot (accuracy)\n",
    "        ax1.set_xlabel(\"Epoch\")\n",
    "        ax1.set_ylabel(\"Train Accuracy\")\n",
    "        ax1.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "        ax1.set_ylim(0, 100)\n",
    "        ax1.legend(loc=\"upper right\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save best damping vs learning rate plot\n",
    "        lr_plot_dir = \"learning_curves\"\n",
    "        os.makedirs(lr_plot_dir, exist_ok=True)\n",
    "        lr_filename = f\"{dataset}_{algorithm}_training_acc_lr.pdf\"\n",
    "        lr_filepath = os.path.join(lr_plot_dir, lr_filename)\n",
    "        plt.savefig(lr_filepath, format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "        plt.show()\n"
   ],
   "id": "32100cf3b71a16c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plot_avg_lr_and_accuracy_schedules(base_dir_template=\"Experiments/selected_results/100_{}_EpochSeed\",  #\"Experiments/selected_results/damping_experiments/100_{}_1e-03_EpochSeedDamping\",\n",
    "                                   seeds=[0, 1, 2, 3, 4],\n",
    "                                   dataset=\"cifar100\",\n",
    "                                   algorithms=[\"SGD\", \"SGD_CLARA\", \"SGD_CLARA_us\", \"Adam\", \"Adam_CLARA\", \"Adam_CLARA_us\", \"D-Adaptation\"]\n",
    "                                   )"
   ],
   "id": "7a0a044d30677ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fc0032d07df7d19",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
