{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Define the Sphere function\n",
    "def sphere(x):\n",
    "    return np.sum(x ** 2)\n",
    "\n",
    "# Gradient of the Sphere function (known)\n",
    "def sphere_gradient(x):\n",
    "    # noise = np.random.randn(*x.shape) * 0.1\n",
    "    return 2 * x  #  + noise\n",
    "\n",
    "cond = 1e6\n",
    "def ellipsoid(x, cond=cond):\n",
    "    return sum(cond**(np.arange(len(x)) / (len(x) - 1 + 1e-9)) * np.asarray(x)**2)\n",
    "\n",
    "def ellipsoid_gradient(x, cond=cond):\n",
    "    return 2 * cond**(np.arange(len(x)) / (len(x) - 1 + 1e-9)) * np.asarray(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def evolution_strategy(f, x, sigma, budget, mu=5, lambda_=10):\n",
    "    dim = len(x0)\n",
    "\n",
    "    # Initialize path variable, decay and damping factors for Cumulative LeArning Rate Adaptation (CLARA)\n",
    "    path = np.zeros(dim)\n",
    "    c = 0.2\n",
    "    d = 0.2\n",
    "    cos_theta = 0\n",
    "\n",
    "    # Initialize return variables\n",
    "    candidate_solutions = []\n",
    "    step_size = []\n",
    "    path_norm = []\n",
    "    step_norm = []\n",
    "    cos_thetas = []\n",
    "\n",
    "    weights = np.linspace(1, 2, mu)  # Assign higher weight to best individuals\n",
    "    weights /= weights.sum()  # Normalize weights to sum to 1\n",
    "\n",
    "    for i in range(budget):\n",
    "        # Generate offspring\n",
    "        pop = np.random.randn(lambda_, dim)\n",
    "\n",
    "        # Select mu best individuals\n",
    "        selected = pop[np.argsort([f(x + sigma * ind) for ind in pop])[:mu]]\n",
    "\n",
    "        # Update current solution\n",
    "        step = np.sum(selected.T * weights, axis=1)\n",
    "        x = x + sigma * step\n",
    "        candidate_solutions.append(x)\n",
    "\n",
    "        # Update mean estimate of cosine of the angle change between current and mean gradient\n",
    "        cos_theta = (1 - c) * cos_theta + np.sqrt(c * (2 - c)) * np.dot(step, path) / (np.linalg.norm(path) * np.linalg.norm(step) + 1e-8)\n",
    "        cos_thetas.append(cos_theta)\n",
    "\n",
    "        # Update path\n",
    "        path = (1 - c) * path + np.sqrt(c * (2 - c)) * step\n",
    "        path_norm.append(np.linalg.norm(path)**2)\n",
    "        step_norm.append(np.linalg.norm(step)**2)\n",
    "\n",
    "        # Update step-size\n",
    "        sigma = sigma * np.exp(d * ((np.linalg.norm(path)**2 / dim) - 1))\n",
    "        step_size.append(sigma)\n",
    "\n",
    "\n",
    "        print(f'Iteration {i}: current fitness = {f(x)}')\n",
    "\n",
    "    return candidate_solutions, step_size, path_norm, step_norm, cos_thetas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def gradient_descent(gradient, x0, lr=0.1, iterations=100):\n",
    "    \"\"\"\n",
    "    Performs gradient descent to minimize a function.\n",
    "\n",
    "    :param gradient: Function that computes the gradient âˆ‡f(x).\n",
    "    :param x0: Initial guess (NumPy array).\n",
    "    :param lr: Learning rate (step size).\n",
    "    :param iterations: Number of iterations.\n",
    "    :return: Final optimized value of x.\n",
    "    \"\"\"\n",
    "    x = x0  # Initialize x\n",
    "    dim = len(x0)  # Get dimension of search space\n",
    "\n",
    "    # Initialize path variable, decay and damping factors for Cumulative LeArning Rate Adaptation (CLARA)\n",
    "    path = np.zeros(dim)\n",
    "    cos_theta = 0\n",
    "    c = 0.2\n",
    "    d = 0.2\n",
    "\n",
    "    # Estimate of average of cos(angle) between 2 Gaussian vectors\n",
    "    # est_angle = average_angle_gaussian_vectors(dim)\n",
    "\n",
    "    # Initialize return variables\n",
    "    candidate_solutions = []\n",
    "    learning_rate = []\n",
    "    path_norm = []\n",
    "    gradient_norm = []\n",
    "    cos_thetas = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "        grad = gradient(x)  # Compute gradient\n",
    "        x = x - lr * grad  # Update step\n",
    "\n",
    "        # Update mean estimate of cosine of the angle change between current and mean gradient\n",
    "        cos_theta = (1 - c) * cos_theta + np.sqrt(c * (2 - c)) * np.dot(grad, path) / (np.linalg.norm(path) * np.linalg.norm(grad) + 1e-8)\n",
    "\n",
    "        # Update path\n",
    "        path = (1 - c) * path + np.sqrt(c * (2 - c)) * grad\n",
    "\n",
    "        # Update learning rate\n",
    "        # lr = lr * np.exp(d * ((np.linalg.norm(path)**2 / dim - 1))\n",
    "        # lr = lr * np.exp(d * (theta))\n",
    "\n",
    "        candidate_solutions.append(x)\n",
    "        learning_rate.append(lr)\n",
    "        path_norm.append(np.linalg.norm(path)**2)\n",
    "        gradient_norm.append(np.linalg.norm(grad)**2)\n",
    "        cos_thetas.append(cos_theta)\n",
    "\n",
    "    print('Optimized x: ', x)\n",
    "\n",
    "    return candidate_solutions, learning_rate, path_norm, gradient_norm, cos_thetas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "x0 = np.ones(2)\n",
    "lr0 = 1e-1  # 1e-3\n",
    "budget = 100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: current fitness = 1.7527359703148113\n",
      "Iteration 1: current fitness = 1.5832250172927407\n",
      "Iteration 2: current fitness = 1.5679570368380213\n",
      "Iteration 3: current fitness = 1.4864114110958275\n",
      "Iteration 4: current fitness = 1.331195546596184\n",
      "Iteration 5: current fitness = 1.2053961653022727\n",
      "Iteration 6: current fitness = 1.1356091510307653\n",
      "Iteration 7: current fitness = 1.0340534466198879\n",
      "Iteration 8: current fitness = 0.903377887519375\n",
      "Iteration 9: current fitness = 0.8373945746406377\n",
      "Iteration 10: current fitness = 0.8132385618512055\n",
      "Iteration 11: current fitness = 0.7067451753022274\n",
      "Iteration 12: current fitness = 0.6316343358325999\n",
      "Iteration 13: current fitness = 0.4742678914369941\n",
      "Iteration 14: current fitness = 0.4049669681690513\n",
      "Iteration 15: current fitness = 0.27868800572670493\n",
      "Iteration 16: current fitness = 0.17583499980475312\n",
      "Iteration 17: current fitness = 0.14900701480045228\n",
      "Iteration 18: current fitness = 0.05984505552862266\n",
      "Iteration 19: current fitness = 0.013112648187128944\n",
      "Iteration 20: current fitness = 0.009916158785536422\n",
      "Iteration 21: current fitness = 0.020733552224368894\n",
      "Iteration 22: current fitness = 0.010864801351380442\n",
      "Iteration 23: current fitness = 0.005138746702737456\n",
      "Iteration 24: current fitness = 0.0007496096465230001\n",
      "Iteration 25: current fitness = 0.006661485633950312\n",
      "Iteration 26: current fitness = 0.011972814324002759\n",
      "Iteration 27: current fitness = 0.0027162235382192893\n",
      "Iteration 28: current fitness = 0.0011488583803226312\n",
      "Iteration 29: current fitness = 0.0008914348647483687\n",
      "Iteration 30: current fitness = 8.81285845560565e-05\n",
      "Iteration 31: current fitness = 0.001117042558474933\n",
      "Iteration 32: current fitness = 0.00030073824536258734\n",
      "Iteration 33: current fitness = 2.770716040272523e-05\n",
      "Iteration 34: current fitness = 0.0001511361082482563\n",
      "Iteration 35: current fitness = 0.0005827630895491498\n",
      "Iteration 36: current fitness = 0.00025919834346810816\n",
      "Iteration 37: current fitness = 4.7278685181141646e-05\n",
      "Iteration 38: current fitness = 1.8141045478684866e-05\n",
      "Iteration 39: current fitness = 2.950539629791659e-05\n",
      "Iteration 40: current fitness = 3.5253036244548056e-05\n",
      "Iteration 41: current fitness = 9.19394489014908e-06\n",
      "Iteration 42: current fitness = 9.968022965870064e-06\n",
      "Iteration 43: current fitness = 3.7348672330789656e-05\n",
      "Iteration 44: current fitness = 3.057452167015235e-05\n",
      "Iteration 45: current fitness = 4.938730279471486e-05\n",
      "Iteration 46: current fitness = 4.222424769893903e-05\n",
      "Iteration 47: current fitness = 2.4628428290325272e-05\n",
      "Iteration 48: current fitness = 1.4282740536063805e-05\n",
      "Iteration 49: current fitness = 6.314110207876419e-06\n",
      "Iteration 50: current fitness = 2.8158301449166932e-06\n",
      "Iteration 51: current fitness = 4.3199089972453597e-07\n",
      "Iteration 52: current fitness = 1.3186190177037898e-07\n",
      "Iteration 53: current fitness = 2.0732340987639205e-07\n",
      "Iteration 54: current fitness = 7.233478147851389e-08\n",
      "Iteration 55: current fitness = 2.7992622852703557e-07\n",
      "Iteration 56: current fitness = 5.26755167984601e-07\n",
      "Iteration 57: current fitness = 2.729216250876602e-07\n",
      "Iteration 58: current fitness = 1.1107852577657551e-07\n",
      "Iteration 59: current fitness = 1.8939255109435737e-07\n",
      "Iteration 60: current fitness = 1.498248744601572e-07\n",
      "Iteration 61: current fitness = 2.0029361684153204e-07\n",
      "Iteration 62: current fitness = 1.4525727857192797e-07\n",
      "Iteration 63: current fitness = 9.836406434006497e-08\n",
      "Iteration 64: current fitness = 3.3397235607367374e-08\n",
      "Iteration 65: current fitness = 4.112775292521867e-08\n",
      "Iteration 66: current fitness = 1.667032061054273e-08\n",
      "Iteration 67: current fitness = 4.5551111371128155e-09\n",
      "Iteration 68: current fitness = 3.891579339940662e-10\n",
      "Iteration 69: current fitness = 2.219067394624846e-12\n",
      "Iteration 70: current fitness = 1.5721366043162195e-10\n",
      "Iteration 71: current fitness = 3.0097406812178817e-10\n",
      "Iteration 72: current fitness = 9.730764363364975e-10\n",
      "Iteration 73: current fitness = 7.951347406627965e-11\n",
      "Iteration 74: current fitness = 4.277235874511618e-10\n",
      "Iteration 75: current fitness = 2.4320339989674025e-10\n",
      "Iteration 76: current fitness = 5.531859889200476e-10\n",
      "Iteration 77: current fitness = 6.312055043596457e-10\n",
      "Iteration 78: current fitness = 2.6857706283084553e-10\n",
      "Iteration 79: current fitness = 8.517396205923841e-11\n",
      "Iteration 80: current fitness = 3.9605230158133235e-11\n",
      "Iteration 81: current fitness = 9.313961679703821e-11\n",
      "Iteration 82: current fitness = 4.343620420206493e-11\n",
      "Iteration 83: current fitness = 2.014745866127729e-11\n",
      "Iteration 84: current fitness = 1.6233503208059064e-11\n",
      "Iteration 85: current fitness = 3.324508294161641e-12\n",
      "Iteration 86: current fitness = 4.3495394787175464e-13\n",
      "Iteration 87: current fitness = 1.1468064037113433e-13\n",
      "Iteration 88: current fitness = 6.480608907607764e-13\n",
      "Iteration 89: current fitness = 9.656206469017668e-13\n",
      "Iteration 90: current fitness = 3.3256230679165787e-13\n",
      "Iteration 91: current fitness = 6.643163373467288e-13\n",
      "Iteration 92: current fitness = 3.3123569479547965e-13\n",
      "Iteration 93: current fitness = 5.913060373397292e-13\n",
      "Iteration 94: current fitness = 6.206297731601569e-13\n",
      "Iteration 95: current fitness = 3.308349835791063e-14\n",
      "Iteration 96: current fitness = 1.654067384186164e-13\n",
      "Iteration 97: current fitness = 1.0194649025660416e-13\n",
      "Iteration 98: current fitness = 7.342476782942965e-14\n",
      "Iteration 99: current fitness = 5.870131474416875e-14\n"
     ]
    }
   ],
   "source": [
    "# candidate_sol, learning_rates, path_norm, grad_norm, cos_theta = gradient_descent(sphere_gradient, x0, lr=lr0, iterations=budget)\n",
    "candidate_sol, learning_rates, path_norm, grad_norm, cos_theta = evolution_strategy(sphere, x0, sigma=lr0, budget=budget)\n",
    "\n",
    "results = [[np.linalg.norm(x)**2 for x in candidate_sol],\n",
    "           learning_rates,\n",
    "           path_norm,\n",
    "           grad_norm,\n",
    "           [path_norm[i] / grad_norm[i] for i in range(len(path_norm))],\n",
    "           cos_theta\n",
    "           ]\n",
    "fig_titles = ['Distance to optimum',\n",
    "              'Learning rate',\n",
    "              'Path norm',\n",
    "              'Gradient/step norm',\n",
    "              'Path-gradient/step ratio',\n",
    "              'Angle between path and current grad./step'\n",
    "              ]\n",
    "y_labels = [r'$\\|x_t\\|^2$',\n",
    "            r'$\\alpha_t$',\n",
    "            r'$\\|p_t\\|^2$',\n",
    "            r'$\\|g_t\\|^2$',\n",
    "            r'$\\|p_t\\|^2 / \\|g_t\\|^2$',\n",
    "            r'$\\cos(\\theta)$'\n",
    "            ]\n",
    "colors = ['r',\n",
    "          'g',\n",
    "          'b',\n",
    "          'c',\n",
    "          'm',\n",
    "          'y'\n",
    "          ]\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(12, 12))  # 2 rows, 2 columns\n",
    "fig.suptitle(f'Vanilla gradient descent on the sphere, D = {str(len(x0))}')\n",
    "\n",
    "for i, ax in enumerate(axes.flat):  # Iterate over subplots\n",
    "    if i == len(results) - 1:\n",
    "        ax.plot(results[i], color=colors[i])\n",
    "    else:\n",
    "        ax.semilogy(results[i], color=colors[i])\n",
    "    ax.set_title(fig_titles[i])\n",
    "    ax.set_xlabel('Iterations')\n",
    "    ax.set_ylabel(y_labels[i])\n",
    "    ax.grid(True)\n",
    "\n",
    "# Adjust layout and show\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
