{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Define the Sphere function\n",
    "def sphere(x):\n",
    "    return np.sum(x ** 2)\n",
    "\n",
    "# Gradient of the Sphere function (known)\n",
    "def sphere_gradient(x):\n",
    "    # noise = np.random.randn(*x.shape) * 0.1\n",
    "    return 2 * x  #  + noise\n",
    "\n",
    "cond = 1e6\n",
    "def ellipsoid(x, cond=cond):\n",
    "    return sum(cond**(np.arange(len(x)) / (len(x) - 1 + 1e-9)) * np.asarray(x)**2)\n",
    "\n",
    "def ellipsoid_gradient(x, cond=cond):\n",
    "    return 2 * cond**(np.arange(len(x)) / (len(x) - 1 + 1e-9)) * np.asarray(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def evolution_strategy(f, x0, sigma, iterations=100, mu=5, lambda_=10):\n",
    "    dim = len(x0)\n",
    "    x = x0\n",
    "\n",
    "    # Initialize path variable, decay and damping factors for Cumulative LeArning Rate Adaptation (CLARA)\n",
    "    path = np.zeros(dim)\n",
    "    c = 0.2\n",
    "    d = 0.2\n",
    "    cos_theta = 0\n",
    "\n",
    "    # Initialize return variables\n",
    "    candidate_solutions = []\n",
    "    step_size = []\n",
    "    path_norm = []\n",
    "    step_norm = []\n",
    "    cos_thetas = []\n",
    "\n",
    "    weights = np.linspace(1, 2, mu)  # Assign higher weight to best individuals\n",
    "    weights /= weights.sum()  # Normalize weights to sum to 1\n",
    "\n",
    "    for i in range(iterations):\n",
    "        # Generate offspring\n",
    "        pop = np.random.randn(lambda_, dim)\n",
    "\n",
    "        # Select mu best individuals\n",
    "        selected = pop[np.argsort([f(x + sigma * ind) for ind in pop])[:mu]]\n",
    "\n",
    "        # Update current solution\n",
    "        step = np.sum(selected.T * weights, axis=1)\n",
    "        x = x + sigma * step\n",
    "        candidate_solutions.append(x)\n",
    "\n",
    "        # Update mean estimate of cosine of the angle change between current and mean gradient\n",
    "        cos_theta = (1 - c) * cos_theta + np.sqrt(c * (2 - c)) * np.dot(step, path) / (np.linalg.norm(path) * np.linalg.norm(step) + 1e-8)\n",
    "        cos_thetas.append(cos_theta)\n",
    "\n",
    "        # Update path\n",
    "        path = (1 - c) * path + np.sqrt(c * (2 - c)) * step\n",
    "        path_norm.append(np.linalg.norm(path)**2)\n",
    "        step_norm.append(np.linalg.norm(step)**2)\n",
    "\n",
    "        # Update step-size\n",
    "        sigma = sigma * np.exp(d * ((np.linalg.norm(path)**2 / dim) - 1))\n",
    "        step_size.append(sigma)\n",
    "\n",
    "\n",
    "        print(f'Iteration {i}: current fitness = {f(x)}')\n",
    "\n",
    "    return candidate_solutions, step_size, path_norm, step_norm, cos_thetas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def gradient_descent(gradient, x0, lr=0.1, iterations=100):\n",
    "    \"\"\"\n",
    "    Performs gradient descent to minimize a function.\n",
    "\n",
    "    :param gradient: Function that computes the gradient âˆ‡f(x).\n",
    "    :param x0: Initial guess (NumPy array).\n",
    "    :param lr: Learning rate (step size).\n",
    "    :param iterations: Number of iterations.\n",
    "    :return: Final optimized value of x.\n",
    "    \"\"\"\n",
    "    x = x0  # Initialize x\n",
    "    dim = len(x0)  # Get dimension of search space\n",
    "\n",
    "    # Initialize path variable, decay and damping factors for Cumulative LeArning Rate Adaptation (CLARA)\n",
    "    path = np.zeros(dim)\n",
    "    cos_theta = 0\n",
    "    c = 0.2\n",
    "    d = 0.2\n",
    "\n",
    "    # Estimate of average of cos(angle) between 2 Gaussian vectors\n",
    "    # est_angle = average_angle_gaussian_vectors(dim)\n",
    "\n",
    "    # Initialize return variables\n",
    "    candidate_solutions = []\n",
    "    learning_rate = []\n",
    "    path_norm = []\n",
    "    gradient_norm = []\n",
    "    cos_thetas = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "        grad = gradient(x)  # Compute gradient\n",
    "        x = x - lr * grad  # Update step\n",
    "\n",
    "        # Update mean estimate of cosine of the angle change between current and mean gradient\n",
    "        cos_theta = (1 - c) * cos_theta + np.sqrt(c * (2 - c)) * np.dot(grad, path) / (np.linalg.norm(path) * np.linalg.norm(grad) + 1e-8)\n",
    "\n",
    "        # Update path\n",
    "        path = (1 - c) * path + np.sqrt(c * (2 - c)) * grad\n",
    "\n",
    "        # Update learning rate\n",
    "        # lr = lr * np.exp(d * ((np.linalg.norm(path)**2 / dim - 1))\n",
    "        # lr = lr * np.exp(d * (theta))\n",
    "\n",
    "        candidate_solutions.append(x)\n",
    "        learning_rate.append(lr)\n",
    "        path_norm.append(np.linalg.norm(path)**2)\n",
    "        gradient_norm.append(np.linalg.norm(grad)**2)\n",
    "        cos_thetas.append(cos_theta)\n",
    "\n",
    "    print('Optimized x: ', x)\n",
    "\n",
    "    return candidate_solutions, learning_rate, path_norm, gradient_norm, cos_thetas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: current fitness = 1.871685516299367\n",
      "Iteration 1: current fitness = 1.78426476593248\n",
      "Iteration 2: current fitness = 1.679100269856466\n",
      "Iteration 3: current fitness = 1.553355162542119\n",
      "Iteration 4: current fitness = 1.5378715969876595\n",
      "Iteration 5: current fitness = 1.4966284555354903\n",
      "Iteration 6: current fitness = 1.4191235277655796\n",
      "Iteration 7: current fitness = 1.3755975226450818\n",
      "Iteration 8: current fitness = 1.2901884984308527\n",
      "Iteration 9: current fitness = 1.272039478192084\n",
      "Iteration 10: current fitness = 1.2339428155560337\n",
      "Iteration 11: current fitness = 1.2084147898545812\n",
      "Iteration 12: current fitness = 1.1821993649679343\n",
      "Iteration 13: current fitness = 1.1409764277017538\n",
      "Iteration 14: current fitness = 1.1172951552408388\n",
      "Iteration 15: current fitness = 1.0867412159951693\n",
      "Iteration 16: current fitness = 1.0370795894530396\n",
      "Iteration 17: current fitness = 0.9641522983494961\n",
      "Iteration 18: current fitness = 0.9273152988990772\n",
      "Iteration 19: current fitness = 0.8645519045152357\n",
      "Iteration 20: current fitness = 0.7884325245539153\n",
      "Iteration 21: current fitness = 0.7411357490097349\n",
      "Iteration 22: current fitness = 0.6779878642177133\n",
      "Iteration 23: current fitness = 0.6341497785533963\n",
      "Iteration 24: current fitness = 0.46180220771923824\n",
      "Iteration 25: current fitness = 0.4719360445730595\n",
      "Iteration 26: current fitness = 0.42857719742508765\n",
      "Iteration 27: current fitness = 0.37359733302896686\n",
      "Iteration 28: current fitness = 0.33150496939024365\n",
      "Iteration 29: current fitness = 0.20640998694014806\n",
      "Iteration 30: current fitness = 0.13837525541881932\n",
      "Iteration 31: current fitness = 0.033189906728538554\n",
      "Iteration 32: current fitness = 0.02515624261957587\n",
      "Iteration 33: current fitness = 0.016840452759103952\n",
      "Iteration 34: current fitness = 0.014644417958109775\n",
      "Iteration 35: current fitness = 0.0020355339043232686\n",
      "Iteration 36: current fitness = 0.007104015293236725\n",
      "Iteration 37: current fitness = 0.007439870016077511\n",
      "Iteration 38: current fitness = 0.005411333427671067\n",
      "Iteration 39: current fitness = 0.00503494055853669\n",
      "Iteration 40: current fitness = 0.0008989017173753497\n",
      "Iteration 41: current fitness = 0.0006655806156137755\n",
      "Iteration 42: current fitness = 0.00026912095327716627\n",
      "Iteration 43: current fitness = 0.00037245238605466133\n",
      "Iteration 44: current fitness = 0.0001949715390975121\n",
      "Iteration 45: current fitness = 4.448103427342532e-05\n",
      "Iteration 46: current fitness = 0.0002259438052222551\n",
      "Iteration 47: current fitness = 9.35041077330985e-06\n",
      "Iteration 48: current fitness = 3.2100051702517824e-05\n",
      "Iteration 49: current fitness = 0.00015697313667447903\n",
      "Iteration 50: current fitness = 3.34946202780648e-05\n",
      "Iteration 51: current fitness = 2.454488441966313e-05\n",
      "Iteration 52: current fitness = 3.809673006032663e-05\n",
      "Iteration 53: current fitness = 3.860880037329621e-05\n",
      "Iteration 54: current fitness = 1.0163197473318248e-06\n",
      "Iteration 55: current fitness = 9.24032029695212e-06\n",
      "Iteration 56: current fitness = 6.338119524642572e-06\n",
      "Iteration 57: current fitness = 6.118959582351113e-07\n",
      "Iteration 58: current fitness = 7.879580274816247e-07\n",
      "Iteration 59: current fitness = 1.9576335105709747e-06\n",
      "Iteration 60: current fitness = 9.73798553076981e-07\n",
      "Iteration 61: current fitness = 8.306259126841362e-07\n",
      "Iteration 62: current fitness = 4.881630921850012e-07\n",
      "Iteration 63: current fitness = 4.5523254078005936e-07\n",
      "Iteration 64: current fitness = 5.026629491368225e-07\n",
      "Iteration 65: current fitness = 5.683271055985936e-07\n",
      "Iteration 66: current fitness = 3.493789810441471e-07\n",
      "Iteration 67: current fitness = 6.12566059924766e-07\n",
      "Iteration 68: current fitness = 1.7150507009781734e-07\n",
      "Iteration 69: current fitness = 1.2385725920154006e-07\n",
      "Iteration 70: current fitness = 2.6918897455925633e-08\n",
      "Iteration 71: current fitness = 1.3743104471494676e-08\n",
      "Iteration 72: current fitness = 1.4322502469397344e-08\n",
      "Iteration 73: current fitness = 1.3559568084400702e-08\n",
      "Iteration 74: current fitness = 6.7303609048249956e-09\n",
      "Iteration 75: current fitness = 3.7395420712273665e-09\n",
      "Iteration 76: current fitness = 4.185455166501229e-09\n",
      "Iteration 77: current fitness = 1.6605835625428566e-10\n",
      "Iteration 78: current fitness = 5.6385267821362e-09\n",
      "Iteration 79: current fitness = 6.777017798594835e-10\n",
      "Iteration 80: current fitness = 1.0314908438761278e-09\n",
      "Iteration 81: current fitness = 4.901501415949284e-10\n",
      "Iteration 82: current fitness = 5.011095767845222e-10\n",
      "Iteration 83: current fitness = 1.6084717790083105e-10\n",
      "Iteration 84: current fitness = 6.61409228183635e-11\n",
      "Iteration 85: current fitness = 8.159057522914055e-13\n",
      "Iteration 86: current fitness = 5.899970835248296e-11\n",
      "Iteration 87: current fitness = 3.54058381580366e-11\n",
      "Iteration 88: current fitness = 9.644291542704368e-12\n",
      "Iteration 89: current fitness = 3.0612422597887444e-12\n",
      "Iteration 90: current fitness = 1.5193609619249017e-11\n",
      "Iteration 91: current fitness = 5.282708195918373e-12\n",
      "Iteration 92: current fitness = 1.971816144793616e-12\n",
      "Iteration 93: current fitness = 4.664964097064424e-12\n",
      "Iteration 94: current fitness = 2.4021897228826638e-11\n",
      "Iteration 95: current fitness = 9.503531048579286e-12\n",
      "Iteration 96: current fitness = 6.979834505924721e-12\n",
      "Iteration 97: current fitness = 2.6035346051978993e-12\n",
      "Iteration 98: current fitness = 3.6870314755505907e-13\n",
      "Iteration 99: current fitness = 2.0252999029507352e-12\n",
      "Iteration 100: current fitness = 1.0737561535081542e-12\n",
      "Iteration 101: current fitness = 2.509558641660479e-12\n",
      "Iteration 102: current fitness = 8.892369058854259e-13\n",
      "Iteration 103: current fitness = 3.238942012869993e-13\n",
      "Iteration 104: current fitness = 3.912466520004482e-13\n",
      "Iteration 105: current fitness = 1.9791163695284365e-13\n",
      "Iteration 106: current fitness = 1.068009078641514e-13\n",
      "Iteration 107: current fitness = 6.9908480832654266e-15\n",
      "Iteration 108: current fitness = 1.4317357868836152e-14\n",
      "Iteration 109: current fitness = 9.71200585219389e-15\n",
      "Iteration 110: current fitness = 2.3604853345635274e-14\n",
      "Iteration 111: current fitness = 1.4088615403034656e-15\n",
      "Iteration 112: current fitness = 4.587429246175324e-15\n",
      "Iteration 113: current fitness = 6.3486094416071145e-15\n",
      "Iteration 114: current fitness = 1.329157478838514e-15\n",
      "Iteration 115: current fitness = 2.2099479332326569e-16\n",
      "Iteration 116: current fitness = 6.128778663377477e-16\n",
      "Iteration 117: current fitness = 8.272273176656826e-16\n",
      "Iteration 118: current fitness = 5.590555263091296e-16\n",
      "Iteration 119: current fitness = 7.404507520056711e-16\n",
      "Iteration 120: current fitness = 1.042826561567344e-15\n",
      "Iteration 121: current fitness = 5.103684777088563e-17\n",
      "Iteration 122: current fitness = 1.5936854355475456e-16\n",
      "Iteration 123: current fitness = 6.146938149156951e-18\n",
      "Iteration 124: current fitness = 1.2821904558242522e-17\n",
      "Iteration 125: current fitness = 3.718191348739501e-17\n",
      "Iteration 126: current fitness = 8.468207410487738e-18\n",
      "Iteration 127: current fitness = 6.482751186032228e-18\n",
      "Iteration 128: current fitness = 8.796540381107057e-19\n",
      "Iteration 129: current fitness = 1.311838483787947e-17\n",
      "Iteration 130: current fitness = 8.593467583588306e-18\n",
      "Iteration 131: current fitness = 9.967515827530638e-18\n",
      "Iteration 132: current fitness = 1.86569208056257e-17\n",
      "Iteration 133: current fitness = 1.3339405589773727e-17\n",
      "Iteration 134: current fitness = 1.1407519924609062e-17\n",
      "Iteration 135: current fitness = 4.654776222784664e-18\n",
      "Iteration 136: current fitness = 4.602043172953994e-18\n",
      "Iteration 137: current fitness = 1.5893900990576322e-18\n",
      "Iteration 138: current fitness = 6.76414384661432e-19\n",
      "Iteration 139: current fitness = 2.2427308925530165e-19\n",
      "Iteration 140: current fitness = 1.0249257135793428e-19\n",
      "Iteration 141: current fitness = 8.551663565564827e-20\n",
      "Iteration 142: current fitness = 2.0218494417428233e-19\n",
      "Iteration 143: current fitness = 2.253182235879099e-19\n",
      "Iteration 144: current fitness = 3.1357384602947135e-20\n",
      "Iteration 145: current fitness = 1.907398806221549e-20\n",
      "Iteration 146: current fitness = 5.3779589293094e-21\n",
      "Iteration 147: current fitness = 2.829246579479385e-21\n",
      "Iteration 148: current fitness = 1.6576787744474515e-20\n",
      "Iteration 149: current fitness = 9.912942871343291e-21\n",
      "Iteration 150: current fitness = 9.131859541491314e-21\n",
      "Iteration 151: current fitness = 1.0866791349412817e-21\n",
      "Iteration 152: current fitness = 9.839280011182694e-22\n",
      "Iteration 153: current fitness = 3.315380179815142e-22\n",
      "Iteration 154: current fitness = 2.6875920436378127e-21\n",
      "Iteration 155: current fitness = 1.6776129252891878e-22\n",
      "Iteration 156: current fitness = 1.477000243096492e-21\n",
      "Iteration 157: current fitness = 1.94056441310399e-22\n",
      "Iteration 158: current fitness = 2.545819208363817e-22\n",
      "Iteration 159: current fitness = 1.194863496233728e-22\n",
      "Iteration 160: current fitness = 2.2478382257350195e-22\n",
      "Iteration 161: current fitness = 1.2909566743293236e-22\n",
      "Iteration 162: current fitness = 2.1557545822498205e-22\n",
      "Iteration 163: current fitness = 1.609444981859155e-22\n",
      "Iteration 164: current fitness = 8.301230529917848e-23\n",
      "Iteration 165: current fitness = 2.86030123010111e-23\n",
      "Iteration 166: current fitness = 1.4611848955363406e-23\n",
      "Iteration 167: current fitness = 2.4176512195747605e-23\n",
      "Iteration 168: current fitness = 2.883496586186276e-23\n",
      "Iteration 169: current fitness = 6.1169117043837455e-24\n",
      "Iteration 170: current fitness = 1.0329257586941002e-23\n",
      "Iteration 171: current fitness = 1.536850853355911e-23\n",
      "Iteration 172: current fitness = 5.1715255163395794e-24\n",
      "Iteration 173: current fitness = 5.666907877076121e-25\n",
      "Iteration 174: current fitness = 1.323942595940975e-24\n",
      "Iteration 175: current fitness = 7.08784908566747e-25\n",
      "Iteration 176: current fitness = 2.0066559743347992e-25\n",
      "Iteration 177: current fitness = 1.9353481666206677e-25\n",
      "Iteration 178: current fitness = 6.418993830377568e-26\n",
      "Iteration 179: current fitness = 1.0741399796031325e-25\n",
      "Iteration 180: current fitness = 9.919472964464733e-26\n",
      "Iteration 181: current fitness = 5.525266642345879e-26\n",
      "Iteration 182: current fitness = 8.910018238667699e-26\n",
      "Iteration 183: current fitness = 7.757907495395358e-26\n",
      "Iteration 184: current fitness = 4.937372344789723e-26\n",
      "Iteration 185: current fitness = 3.350481949809752e-26\n",
      "Iteration 186: current fitness = 5.9608172106901044e-27\n",
      "Iteration 187: current fitness = 1.1730417468089972e-26\n",
      "Iteration 188: current fitness = 6.915154299402735e-27\n",
      "Iteration 189: current fitness = 5.246517100900241e-27\n",
      "Iteration 190: current fitness = 2.5438936455133014e-27\n",
      "Iteration 191: current fitness = 2.8875063092960052e-27\n",
      "Iteration 192: current fitness = 1.4618700005767495e-28\n",
      "Iteration 193: current fitness = 9.036051931620408e-29\n",
      "Iteration 194: current fitness = 3.2725771686071306e-28\n",
      "Iteration 195: current fitness = 1.8822709318024274e-28\n",
      "Iteration 196: current fitness = 2.3447811571941635e-28\n",
      "Iteration 197: current fitness = 1.5507423682875156e-28\n",
      "Iteration 198: current fitness = 1.6954300366612633e-28\n",
      "Iteration 199: current fitness = 3.651338165738971e-29\n"
     ]
    }
   ],
   "source": [
    "dim = 2\n",
    "x0 = np.ones(2)\n",
    "lr0 = 1e-1  # 1e-3\n",
    "budget = 200\n",
    "\n",
    "choice = 1\n",
    "\n",
    "if choice == 0:\n",
    "    optimizer = gradient_descent  # evolution_strategy\n",
    "    f = sphere_gradient\n",
    "    fig_title = 'Vanilla gradient descent'  # '(mu, lambda)-ES'\n",
    "else:\n",
    "    optimizer = evolution_strategy\n",
    "    f = sphere\n",
    "    fig_title = '(mu, lambda)-ES'\n",
    "\n",
    "candidate_sol, learning_rates, path_norm, grad_norm, cos_theta = optimizer(f, x0, lr0, iterations=budget)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "results = [[np.linalg.norm(x)**2 for x in candidate_sol],\n",
    "           learning_rates,\n",
    "           path_norm,\n",
    "           grad_norm,\n",
    "           [path_norm[i] / grad_norm[i] for i in range(len(path_norm))],  # grad_norm[i]\n",
    "           cos_theta\n",
    "           ]\n",
    "fig_titles = ['Distance to optimum',\n",
    "              'Learning rate',\n",
    "              'Path norm',\n",
    "              'Gradient/step norm',\n",
    "              'Path-gradient/step ratio',\n",
    "              'Angle between path and current grad./step'\n",
    "              ]\n",
    "y_labels = [r'$\\|x_t\\|^2$',\n",
    "            r'$\\alpha_t$',\n",
    "            r'$\\|p_t\\|^2$',\n",
    "            r'$\\|g_t\\|^2$',\n",
    "            r'$\\|p_t\\|^2 / \\|g_t\\|^2$',\n",
    "            r'$\\cos(\\theta)$'\n",
    "            ]\n",
    "colors = ['r',\n",
    "          'g',\n",
    "          'b',\n",
    "          'c',\n",
    "          'm',\n",
    "          'y'\n",
    "          ]\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(12, 12))  # 2 rows, 2 columns\n",
    "fig.suptitle(f'{fig_title} on the sphere, D = {str(len(x0))}')\n",
    "\n",
    "for i, ax in enumerate(axes.flat):  # Iterate over subplots\n",
    "    if i == len(results) - 1:\n",
    "        ax.plot(results[i], color=colors[i])\n",
    "    else:\n",
    "        ax.semilogy(results[i], color=colors[i])\n",
    "    ax.set_title(fig_titles[i])\n",
    "    ax.set_xlabel('Iterations')\n",
    "    ax.set_ylabel(y_labels[i])\n",
    "    ax.grid(True)\n",
    "\n",
    "# Adjust layout and show\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
