{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib tk\n",
    "import ast\n",
    "import re\n",
    "import json\n",
    "from tabulate import tabulate\n",
    "import sys\n",
    "import os\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import gymnasium as gym\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "ppo_experiments_dir = os.path.join(current_dir, \"ppo_experiments\")\n",
    "sys.path.append(ppo_experiments_dir)\n",
    "\n",
    "from ppo_experiments.utilities import plot_multiple_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Global variables\n",
    "gymnasium_envs = ['LunarLander-v3',\n",
    "                  'BipedalWalker-v3',\n",
    "                  # 'Pong-v5',\n",
    "                  # 'Ant-v5',\n",
    "                  # 'Humanoid-v5'\n",
    "                  ]\n",
    "n_models = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_best_and_median_policy_results(experiment_dir):\n",
    "    \"\"\"\n",
    "    Retrieve cumul. reward and episode length statistics on test environments for the best and median policies from log files\n",
    "    generated during the experiment.\n",
    "    :param experiment_dir: Path to experiment directory\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # Parse experiment path to extract env. config.\n",
    "    match = re.search(r'(\\d+)containers_(\\d+)presses', experiment_dir)\n",
    "    env_name = None\n",
    "\n",
    "    if match:\n",
    "        num_containers = int(match.group(1))\n",
    "        num_presses = int(match.group(2))\n",
    "        env_name = 'n' + str(num_containers) + '_m' + str(num_presses)\n",
    "        # print(f'Containers: {num_containers}, Presses: {num_presses}')\n",
    "    else:\n",
    "        for env in gymnasium_envs:\n",
    "            if env in experiment_dir:\n",
    "                match = True\n",
    "                env_name = env\n",
    "                break\n",
    "\n",
    "    if not match:\n",
    "        print('Invalid experiment directory.')\n",
    "        return False\n",
    "\n",
    "    with open(experiment_dir + 'test_results.txt', 'r') as file:  # TODO: Include '/' in experiment_dir or '/test_results.txt'?\n",
    "        data = file.read()\n",
    "\n",
    "    # Extracting the list of models from the data\n",
    "    models_str = data.split('Mean and std dev of all ' + str(n_models) + ' models:\\n')[1].split('Best model')[0].strip()\n",
    "    models = ast.literal_eval(models_str)\n",
    "\n",
    "    # Extract best and median seeds from the file\n",
    "    best_seed_match = re.search(r'Best model \\(seed=(\\d+)\\)', data)\n",
    "    median_seed_match = re.search(r'Median model \\(seed=(\\d+)\\)', data)\n",
    "\n",
    "    best_seed = int(best_seed_match.group(1))\n",
    "    median_seed = int(median_seed_match.group(1))\n",
    "\n",
    "    best_model_res = [x[1] for x in models if x[0] == best_seed][0]\n",
    "    median_model_res = [x[1] for x in models if x[0] == median_seed][0]\n",
    "\n",
    "    return env_name, best_seed, best_model_res, median_seed, median_model_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_best_and_median_lr(best_policy_dir, median_policy_dir, title=None):\n",
    "    \"\"\"\n",
    "    Plot best and median policy training learning rates. Relevant in particular when an adaptive learning rate strategy is used by the optimizer.\n",
    "    :param best_policy_dir: Best policy directory\n",
    "    :param median_policy_dir: Median policy directory\n",
    "    :param title: Desired plot title\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    df1 = pd.read_csv(best_policy_dir + 'learning_rates.csv')\n",
    "    df2 = pd.read_csv(median_policy_dir + 'learning_rates.csv')\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.semilogy(df1.iloc[:, 0], df1.iloc[:, 1], linestyle='-', color='b', label='Best')\n",
    "    ax.semilogy(df2.iloc[:, 0], df2.iloc[:, 1], linestyle='--', color='r', label='Median')\n",
    "\n",
    "    ax.set_xlabel('Timesteps')\n",
    "    ax.set_ylabel('Learning rate')\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    else:\n",
    "        ax.set_title(\"Training learning rate\")\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def exponential_smoothing(arrays, alpha=0.2):\n",
    "    \"\"\"Applies exponential smoothing to a list of NumPy arrays.\"\"\"\n",
    "    smoothed = [arrays[0]]  # Initialize with first value\n",
    "\n",
    "    for i in range(1, len(arrays)):\n",
    "        smoothed_value = alpha * arrays[i] + (1 - alpha) * smoothed[-1]\n",
    "        smoothed.append(smoothed_value)\n",
    "\n",
    "    return smoothed  # np.array(smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_cumul_path_distrib_mean_vs_dim(l_dim, l_peaks, title=None):\n",
    "    \"\"\"\n",
    "    :param l_dim: list of #params to plot against (dimensionality of the problem)\n",
    "    :param l_peaks: list of peaks of \\|p_t\\| values for median seeds/models\n",
    "    :param title: plot title\n",
    "    :return: figure\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    # for dim, peaks in zip(l_dim, l_peaks):  # If l_peaks is a list of lists\n",
    "    #     ax.scatter([dim] * len(peaks), peaks)\n",
    "\n",
    "    ax.plot(l_dim, l_peaks, marker='o',  markeredgewidth=2, linewidth=3)\n",
    "    ax.set_xticks(l_dim)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(r'$D$')\n",
    "    ax.set_ylabel(r'Mean of $\\|p_t\\|$ distribution (median seed)')\n",
    "    ax.grid(True)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def estimate_gradients_variance(experiment_dir, title=None):\n",
    "    variances = []\n",
    "    for seed in range(n_models):\n",
    "        with open(f\"{experiment_dir}/{seed:02d}/adam_updates.json\", 'r') as f:\n",
    "             data = json.load(f)  # Load JSON content\n",
    "        df = pd.DataFrame(data)\n",
    "        column = 'adam_update'\n",
    "        df[column] = df[column].apply(np.array)\n",
    "\n",
    "        # Convert the column of arrays into a single 2D NumPy array\n",
    "        vectors_matrix = np.stack(df[column].values)\n",
    "\n",
    "        # Compute variance for each dimension\n",
    "        variances.append(np.median(np.var(vectors_matrix, axis=0, ddof=1)))  # Unbiased estimate\n",
    "\n",
    "    # var = np.median(np.concatenate(variances))\n",
    "\n",
    "    # plt.grid(True)\n",
    "    # plt.legend()\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    return variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_adam_steps(experiment_dir, title=None, c=0.1, d=1):\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(8, 9))\n",
    "    adam_step_label = r'$\\frac{\\|\\hat{m}_t / (\\sqrt{\\hat{v_t}} + \\epsilon)\\|^2}{\\nu_t D}$'\n",
    "    if title:\n",
    "        axes[0].set_title(title)\n",
    "    axes[0].set_xlabel('Timesteps')\n",
    "    axes[0].set_ylabel(adam_step_label)\n",
    "\n",
    "    axes[1].set_title(r'Distribution of ' + adam_step_label)\n",
    "    axes[1].set_xlabel(adam_step_label)\n",
    "\n",
    "    axes[2].set_xlabel('Timesteps')\n",
    "    axes[2].set_ylabel('Learning rate')\n",
    "\n",
    "    _, best_seed, _, median_seed, _ = get_best_and_median_policy_results(experiment_dir)\n",
    "\n",
    "    density_plot = None\n",
    "\n",
    "    for seed in range(n_models):\n",
    "        with open(f\"{experiment_dir}/{seed:02d}/adam_updates.json\", 'r') as f:\n",
    "             data = json.load(f)  # Load JSON content\n",
    "        df = pd.DataFrame(data)\n",
    "        column = 'adam_update'\n",
    "        df[column] = df[column].apply(np.array)\n",
    "        # df['cumul_path'] = exponential_smoothing(df[column].to_list(), alpha=1)\n",
    "        D = len(df[column].iloc[-1])\n",
    "\n",
    "        df['var'] = df[column].apply(lambda x: np.var(x))\n",
    "        df['var'] = df['var'].ewm(alpha=c, adjust=False).mean()\n",
    "        df['norm_step'] = df[column].apply(lambda x: np.linalg.norm(x)**2)\n",
    "        df['norm_step'] = df['norm_step'] / (df['var'] * D)\n",
    "\n",
    "        df_lr = pd.read_csv(f\"{experiment_dir}/{seed:02d}/\" + 'learning_rates.csv')\n",
    "\n",
    "        # df['lr'] = df_lr['learning_rate'].iloc[1:].values\n",
    "\n",
    "        if seed == best_seed:\n",
    "            axes[0].semilogy(df['timestep'], df['norm_step'], label='Best')\n",
    "            density_plot = df['norm_step'].plot.kde(ax=axes[1], label='Best')\n",
    "            axes[2].plot(df_lr['timestep'], df_lr['learning_rate'], label='Best')\n",
    "\n",
    "        elif seed == median_seed:\n",
    "            axes[0].semilogy(df['timestep'], df['norm_step'], label='Median')\n",
    "            density_plot = df['norm_step'].plot.kde(ax=axes[1], label='Median')\n",
    "            axes[2].plot(df_lr['timestep'], df_lr['learning_rate'], label='Median')\n",
    "        else:\n",
    "            axes[0].semilogy(df['timestep'], df['norm_step'])\n",
    "            density_plot = df['norm_step'].plot.kde(ax=axes[1], label='_')\n",
    "            axes[2].plot(df_lr['timestep'], df_lr['learning_rate'])\n",
    "\n",
    "    # Extract peaks of path norm density plots\n",
    "    line = density_plot.get_lines()[median_seed]\n",
    "    x, y = line.get_xdata(), line.get_ydata()\n",
    "\n",
    "    # Find the x value where the density is highest\n",
    "    density_peak = x[np.argmax(y)]\n",
    "\n",
    "    axes[0].grid(True), axes[1].grid(True), axes[2].grid(True)\n",
    "    axes[0].legend(), axes[1].legend(), axes[2].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    return fig, D, density_peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit_and_save_linear_model(x, y, model_path='linear_model.pkl', x_label=r'$D$', y_label='Peak of ' + r'$\\frac{\\|\\hat{m}_t / (\\sqrt{\\hat{v_t}} + \\epsilon)\\|^2}{\\sigma^2 D}$' + ' distribution (median seed)'):\n",
    "    \"\"\"\n",
    "    Fits a linear regression model to the given data, saves it to a file, and returns the trained model.\n",
    "    \"\"\"\n",
    "    x = np.array(x).reshape(-1, 1)  # Ensure x is a column vector\n",
    "    y = np.array(y)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(x, y)\n",
    "\n",
    "    # Save the model\n",
    "    joblib.dump(model, model_path)\n",
    "\n",
    "    print(f'Model saved to {model_path}')\n",
    "\n",
    "     # Predict y-values for the given x\n",
    "    y_pred = model.predict(x)\n",
    "\n",
    "    # Plot the results\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title('Linear approximation')\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.plot(x, y, color='blue', label='Data', marker='o', linestyle='--')\n",
    "    ax.plot(x, y_pred, color='red', linewidth=2, label='Fitted line')\n",
    "    ax.set_xticks(x.ravel())\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "\n",
    "    return model\n",
    "\n",
    "# Example usage\n",
    "# x = [1, 2, 3, 4, 5]\n",
    "# y = [2.2, 2.8, 3.6, 4.5, 5.1]\n",
    "\n",
    "# model = fit_and_save_linear_model(x, y)\n",
    "\n",
    "# Load the model later for use\n",
    "# loaded_model = joblib.load('linear_model.pkl')\n",
    "# print(f\"Loaded Model Coefficients: {loaded_model.coef_[0]}, Intercept: {loaded_model.intercept_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def display_results(experiments_dir, plot_figs=True):\n",
    "    # TODO: Adjust y-label on best & median learning rate plots\n",
    "    env_configs = []  # Labels for env. configurations\n",
    "    configs_dir = []\n",
    "    if 'containergym' in experiments_dir:\n",
    "        n_container_values = [5, 5, 11, 11]\n",
    "        n_pu_values = [2, 5, 2, 11]\n",
    "        for n, m in zip(n_container_values, n_pu_values):\n",
    "             env_configs.append('n' + str(n) + '_m' + str(m))\n",
    "             configs_dir.append(str(n) + 'containers_' + str(m) + 'presses_timestep_2min/')\n",
    "    else:\n",
    "        env_configs = gymnasium_envs\n",
    "\n",
    "    # Best model stats\n",
    "    best_rewards = []\n",
    "    best_std_rewards = []\n",
    "    best_lengths = []\n",
    "    best_std_lengths = []\n",
    "\n",
    "    # Median model stats\n",
    "    median_rewards = []\n",
    "    median_std_rewards = []\n",
    "    median_lengths = []\n",
    "    median_std_lengths = []\n",
    "\n",
    "    lr_figs = []\n",
    "\n",
    "    l_dim = []\n",
    "    l_peaks = []\n",
    "\n",
    "    for i in range(len(env_configs)):\n",
    "        if 'containergym' in experiments_dir:\n",
    "            path = experiments_dir + configs_dir[i]\n",
    "        else:\n",
    "            path = experiments_dir + env_configs[i] + '/'\n",
    "        _, best_seed, best, median_seed, median = get_best_and_median_policy_results(path)\n",
    "        best_rewards.append(best['avg_reward']), best_std_rewards.append(best['std_reward'])\n",
    "        best_lengths.append(best['avg_length']), best_std_lengths.append(best['std_length'])\n",
    "\n",
    "        median_rewards.append(median['avg_reward']), median_std_rewards.append(median['std_reward'])\n",
    "        median_lengths.append(median['avg_length']), median_std_lengths.append(median['std_length'])\n",
    "\n",
    "        if plot_figs:\n",
    "            # Plot training learning rates\n",
    "            # lr_figs.append(plot_best_and_median_lr(path + '{:02}'.format(best_seed) + '/', path + '{:02}'.format(median_seed) + '/', env_configs[i]))\n",
    "\n",
    "            # Plot learning curves (training return) per env. config.\n",
    "            log_dirs = []\n",
    "            for seed in range(n_models):\n",
    "                log_dir = f'{path}/{seed:02d}/'\n",
    "                log_dirs.append(log_dir)\n",
    "\n",
    "            plot_multiple_results(log_dirs, title='Smoothed training rewards on ' + env_configs[i], window_size=50)\n",
    "\n",
    "            # Plot gradient norms\n",
    "            if 'dadaptation' not in experiments_dir and 'prodigy' not in experiments_dir:\n",
    "                _, D, density_peaks = plot_adam_steps(path, title='Norm of Adam cumulative path on ' + env_configs[i])\n",
    "\n",
    "                # Prepare lists for path's highest density plots\n",
    "                l_dim.append(D)\n",
    "                l_peaks.append(density_peaks)  # ([p/D for p in density_peaks])\n",
    "\n",
    "    # Train linear model for path mean value as a function of a model's #params\n",
    "    if 'dadaptation' not in experiments_dir and 'prodigy' not in experiments_dir:\n",
    "        _ = fit_and_save_linear_model(l_dim, l_peaks)\n",
    "\n",
    "    # Print test results for best and median policies\n",
    "    print('Best policy statistics:')\n",
    "    headers = ['Config.', 'Cumul. r', 'Std. cumul. r', 'Episode length', 'Std. episode length']\n",
    "    table = zip(env_configs, best_rewards, best_std_rewards, best_lengths, best_std_lengths)\n",
    "    print(tabulate(table, headers=headers, floatfmt='.2f'))\n",
    "\n",
    "    print('\\n')\n",
    "    print('Median policy statistics:')\n",
    "    headers = ['Config.', 'Cumul. r', 'Std. cumul. r', 'Episode length', 'Std. episode length']\n",
    "    table = zip(env_configs, median_rewards, median_std_rewards, median_lengths, median_std_lengths)\n",
    "    print(tabulate(table, headers=headers, floatfmt='.2f'))\n",
    "\n",
    "    if plot_figs:\n",
    "        x = np.arange(len(env_configs))  # Position for bars\n",
    "        width = 0.35  # Width of the bars\n",
    "\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "        # ----- BAR PLOT: Reward Comparison -----\n",
    "        ax[0].bar(x - width/2, best_rewards, width, yerr=best_std_rewards, label='Best', capsize=5, color='b', alpha=0.7)\n",
    "        ax[0].bar(x + width/2, median_rewards, width, yerr=median_std_rewards, label='Median', capsize=5, color='r', alpha=0.7)\n",
    "        ax[0].set_ylabel('Cumulative reward')\n",
    "        ax[0].set_title('Best vs. median policy - Cumulative reward')\n",
    "        ax[0].grid(True)\n",
    "        ax[0].set_xticks(x)\n",
    "        ax[0].set_xticklabels(env_configs)\n",
    "        ax[0].legend()\n",
    "\n",
    "        # ----- LINE PLOT: Episode Length Comparison -----\n",
    "        ax[1].errorbar(env_configs, best_lengths, yerr=best_std_lengths, label='Best', marker='o', linestyle='-', color='b', capsize=5)\n",
    "        ax[1].errorbar(env_configs, median_lengths, yerr=median_std_lengths, label='Median', marker='D', linestyle='-', color='r', capsize=5)\n",
    "        ax[1].set_ylabel('Episode length')\n",
    "        ax[1].set_ylim(0)\n",
    "        ax[1].grid(True)\n",
    "        ax[1].set_title('Best vs. median policy - Episode length')\n",
    "        ax[1].legend()\n",
    "\n",
    "        # plot_cumul_path_distrib_mean_vs_dim(l_dim, l_peaks)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiments_dir = '/local/aatamna/ppo_adam_linear_schedule_gymnasium/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/local/aatamna/ppo_adam_linear_schedule_gymnasium/LunarLander-v3/test_results.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdisplay_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiments_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_figs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 36\u001b[0m, in \u001b[0;36mdisplay_results\u001b[0;34m(experiments_dir, plot_figs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     path \u001b[38;5;241m=\u001b[39m experiments_dir \u001b[38;5;241m+\u001b[39m env_configs[i] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 36\u001b[0m _, best_seed, best, median_seed, median \u001b[38;5;241m=\u001b[39m \u001b[43mget_best_and_median_policy_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m best_rewards\u001b[38;5;241m.\u001b[39mappend(best[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_reward\u001b[39m\u001b[38;5;124m'\u001b[39m]), best_std_rewards\u001b[38;5;241m.\u001b[39mappend(best[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd_reward\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     38\u001b[0m best_lengths\u001b[38;5;241m.\u001b[39mappend(best[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_length\u001b[39m\u001b[38;5;124m'\u001b[39m]), best_std_lengths\u001b[38;5;241m.\u001b[39mappend(best[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd_length\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[4], line 29\u001b[0m, in \u001b[0;36mget_best_and_median_policy_results\u001b[0;34m(experiment_dir)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid experiment directory.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexperiment_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest_results.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:  \u001b[38;5;66;03m# TODO: Include '/' in experiment_dir or '/test_results.txt'?\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     data \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Extracting the list of models from the data\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m     )\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/local/aatamna/ppo_adam_linear_schedule_gymnasium/LunarLander-v3/test_results.txt'"
     ]
    }
   ],
   "source": [
    "display_results(experiments_dir, plot_figs=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lr_adaptation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
